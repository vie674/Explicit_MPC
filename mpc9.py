from time import sleep
import threading
import cv2
import time
import math
import serial
import numpy as np
import cvxpy as cp
from scipy.signal import cont2discrete
import matplotlib.pyplot as plt
from collections import deque
import queue
import pickle
from scipy.spatial import KDTree

shared_data = {
    "encoder_value": None,
    "cte":None,
    "relative_yaw_angle": None,
}
data_lock = threading.Lock()

vidcap = cv2.VideoCapture("output_video.mp4")

# Khá»Ÿi táº¡o danh sÃ¡ch lÆ°u trá»¯ dá»¯ liá»‡u Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“
# ðŸ“Œ 1. Táº£i LUT tá»« file pickle
with open("lookup_table.pkl", "rb") as f:
    lookup_table = pickle.load(f)

# ðŸ“Œ 2. XÃ¢y dá»±ng KDTree tá»« cÃ¡c key trong LUT
lut_keys = np.array(list(lookup_table.keys()))  # Chuyá»ƒn danh sÃ¡ch key thÃ nh máº£ng NumPy
tree = KDTree(lut_keys)  # Táº¡o cÃ¢y KDTree Ä‘á»ƒ tÄƒng tá»‘c tÃ¬m kiáº¿m
def get_nearest_control(x0):
    """
    HÃ m tÃ¬m giÃ¡ trá»‹ Ä‘iá»u khiá»ƒn gáº§n nháº¥t tá»« LUT báº±ng KDTree.

    Args:
        x0 (numpy.array): Tráº¡ng thÃ¡i Ä‘áº§u vÃ o (vector 4 chiá»u).

    Returns:
        float: GiÃ¡ trá»‹ Ä‘iá»u khiá»ƒn tá»‘i Æ°u gáº§n nháº¥t (Ä‘á»™).
    """
    key = tuple(np.round(x0, 2))  # LÃ m trÃ²n Ä‘áº§u vÃ o Ä‘á»ƒ khá»›p key LUT
    dist, idx = tree.query(key)  # TÃ¬m chá»‰ sá»‘ cá»§a Ä‘iá»ƒm gáº§n nháº¥t
    nearest_key = tuple(lut_keys[idx])  # Láº¥y key gáº§n nháº¥t
    return - np.rad2deg(lookup_table[nearest_key][0])  # Chuyá»ƒn tá»« radian sang Ä‘á»™


step_counter = 0  # Biáº¿n Ä‘áº¿m thá»i gian
# Serial port setup
#ser = serial.Serial('/dev/ttyACM0', 115200, timeout=1)
denta = 0
mid = 80
lane_offset = 0
pre_lane_offset = 0
curvature = 0
cur = np.array([[0], [0], [0], [0], [0]])
anlge_inclination_wrt_x = 0
anlge_inclination_wrt_y =0
pre_inclination_wrt_y = 0
x0 = np.array([[0], [0], [0], [0]])

N = 5
v_k = np.array([[0], [0], [0], [0], [0]])

# Biáº¿n toÃ n cá»¥c
A_d, B1_d, B2_d, AX, BU, BV, H, umin, umax, x, u = None, None, None, None, None, None, None, None, None, None, None

C = np.eye(4)  # Quan sÃ¡t toÃ n bá»™ tráº¡ng thÃ¡i
Q = np.diag([0.02, 1, 0.02, 1])  # Nhiá»…u quÃ¡ trÃ¬nh
R = np.diag([0.000001, 0.01, 0.000001, 0.01])  # Nhiá»…u Ä‘o lÆ°á»ng

# Hiá»‡p phÆ°Æ¡ng sai ban Ä‘áº§u vÃ  tráº¡ng thÃ¡i ban Ä‘áº§u
P = np.eye(4)*0.0001
x_hat = np.zeros((4, 1))


def kalman_predict(u, w):
    """
    BÆ°á»›c dá»± Ä‘oÃ¡n cá»§a bá»™ lá»c Kalman
    - A, B1, B2: Ma tráº­n tráº¡ng thÃ¡i vÃ  Ä‘iá»u khiá»ƒn
    - Q: Ma tráº­n nhiá»…u quÃ¡ trÃ¬nh
    - P: Hiá»‡p phÆ°Æ¡ng sai hiá»‡n táº¡i
    - x_hat: Tráº¡ng thÃ¡i hiá»‡n táº¡i
    - u: Äáº§u vÃ o Ä‘iá»u khiá»ƒn (gÃ³c Ä‘Ã¡nh lÃ¡i)
    - w: Nhiá»…u bÃªn ngoÃ i
    """
    u = np.atleast_2d(u).reshape(-1, 1)
    w = np.atleast_2d(w).reshape(-1, 1)
    global A_d, B1_d, B2_d,Q,P,x_hat
    x_hat = A_d @ x_hat + B1_d @ u + B2_d @ w
    P = A_d @ P @ A_d.T + Q
    return x_hat, P

def kalman_update(z):
    """
    BÆ°á»›c cáº­p nháº­t cá»§a bá»™ lá»c Kalman
    - C: Ma tráº­n quan sÃ¡t
    - R: Ma tráº­n nhiá»…u Ä‘o lÆ°á»ng
    - P: Hiá»‡p phÆ°Æ¡ng sai hiá»‡n táº¡i
    - x_hat: Tráº¡ng thÃ¡i hiá»‡n táº¡i
    - z: Dá»¯ liá»‡u Ä‘o lÆ°á»ng thá»±c táº¿
    """
    global  C, R, P, x_hat
    S = C @ P @ C.T + R
    K = P @ C.T @ np.linalg.inv(S)
    x_hat = x_hat + K @ (z - C @ x_hat)
    P = (np.eye(len(P)) - K @ C) @ P
    return x_hat, P

def kalman_step(u, w, z):
    """
    Cáº­p nháº­t Kalman má»™t bÆ°á»›c
    - u: Äáº§u vÃ o Ä‘iá»u khiá»ƒn (gÃ³c Ä‘Ã¡nh lÃ¡i)
    - w: Nhiá»…u bÃªn ngoÃ i (tá»‘c Ä‘á»™ giÃ³, Ä‘á»‹a hÃ¬nh, v.v.)
    - z: Äo lÆ°á»ng thá»±c táº¿ tá»« cáº£m biáº¿n
    """
    global x_hat,P
    x_hat, P = kalman_predict(u, w)
    x_hat, P = kalman_update( z)
    return x_hat, P


def mpc_init(Ts=0.1):
    global A_d, B1_d, B2_d, AX, BU, BV, H, umin, umax, x, u,N

    # --- Há»† THá»NG ---
    m = 2.3
    Lf = 0.12
    Lr = 0.132
    Caf = 70
    Car = 70
    Iz = 0.04
    Vx = 0.4

    # Ma tráº­n Ä‘á»™ng há»c
    A_c = np.array([[0, 1, 0, 0],
                    [0, -(2 * Caf + 2 * Car) / (m * Vx), (2 * Caf + 2 * Car) / m,
                     (-2 * Caf * Lf + 2 * Car * Lr) / (m * Vx)],
                    [0, 0, 0, 1],
                    [0, (-2 * Caf * Lf + 2 * Car * Lr) / (Iz * Vx), (2 * Caf * Lf - 2 * Car * Lr) / Iz,
                     (-2 * Caf * Lf ** 2 - 2 * Car * Lr ** 2) / (Iz * Vx)]])

    B1_c = np.array([[0],
                     [2 * Caf / m],
                     [0],
                     [2 * Caf * Lf / Iz]])

    B2_c = np.array([[0],
                     [(-2 * Caf * Lf + 2 * Car * Lr) / (m * Vx) - Vx],
                     [0],
                     [(-2 * Caf * Lf ** 2 - 2 * Car * Lr ** 2) / (Iz * Vx)]])

    (A_d, B_d, _, _, _) = cont2discrete((A_c, np.hstack((B1_c, B2_c)), np.eye(4), np.zeros((4, 1))), Ts, method='zoh')
    B1_d = B_d[:, [0]]
    B2_d = B_d[:, [1]]

    # ThÃ´ng sá»‘ MPC
    n, m = 4, 1
    Q = np.diag([100, 0, 10, 0])
    QN = Q
    R = np.eye(m) * 6


    AX = np.vstack([np.linalg.matrix_power(A_d, i) for i in range(N + 1)])

    BU = np.zeros(((N + 1) * n, N * m))
    for i in range(1, N + 1):
        for j in range(N):
            if i - j - 1 >= 0:
                BU[i * n:(i + 1) * n, j * m:(j + 1) * m] = (np.linalg.matrix_power(A_d, i - j - 1) @ B1_d).reshape(n, m)

    BV = np.zeros(((N + 1) * n, N * m))
    for i in range(1, N + 1):
        for j in range(i):
            if i - j - 1 >= 0:
                BV[i * n:(i + 1) * n, j * m:(j + 1) * m] = (np.linalg.matrix_power(A_d, i - j - 1) @ B2_d).reshape(n, m)

    QX = np.kron(np.eye(N), Q)
    RU = np.kron(np.eye(N), R)
    QX = np.block([[QX, np.zeros((N * n, n))], [np.zeros((n, N * n)), QN]])
    H = np.block([[QX, np.zeros((QX.shape[0], RU.shape[1]))],
                  [np.zeros((RU.shape[0], QX.shape[1])), RU]])
    H += np.eye(H.shape[0]) * 1e-6

    # Khá»Ÿi táº¡o tráº¡ng thÃ¡i vÃ  Ä‘iá»u khiá»ƒn




def mpc_control():
    global A_d, B1_d, B2_d, AX, BU, BV, H, umin, umax, N,x0,v_k
    umin, umax = -7 * np.pi / 36, 7 * np.pi / 36
    xk = x0.reshape(-1, 1)
    v_k = cur
    z = cp.Variable(((N + 1) * 4 + N * 1, 1))
    cost = cp.quad_form(z, H)
    constraints = [
        z[: (N + 1) * 4] == AX @ xk + BU @ z[(N + 1) * 4:] + BV @ v_k,
        z[(N + 1) * 4:] >= umin, z[(N + 1) * 4:] <= umax
    ]

    prob = cp.Problem(cp.Minimize(cost), constraints)
    prob.solve()

    if prob.status not in ["optimal", "optimal_inaccurate"]:
        print(f"[âŒ] MPC khÃ´ng tÃ¬m tháº¥y nghiá»‡m. Tráº¡ng thÃ¡i solver: {prob.status}")
        return None
    print(f"hh {z.value[(N + 1) * 4:(N + 1) * 4 + 1].flatten().item()}")
    value_rad = z.value[(N + 1) * 4:(N + 1) * 4 + 1].flatten().item()
    value_deg = np.rad2deg(value_rad)  # Chuyá»ƒn tá»« radian sang Ä‘á»™
    return - value_deg


class PID:
    def __init__(self, Kp, Ki, Kd, min_output=-35, max_output=35):
        """
        Khá»Ÿi táº¡o PID controller.
        - Kp: Há»‡ sá»‘ tá»‰ lá»‡ (Proportional)
        - Ki: Há»‡ sá»‘ tÃ­ch phÃ¢n (Integral)
        - Kd: Há»‡ sá»‘ Ä‘áº¡o hÃ m (Derivative)
        - min_output: GiÃ¡ trá»‹ giá»›i háº¡n dÆ°á»›i cho gÃ³c lÃ¡i
        - max_output: GiÃ¡ trá»‹ giá»›i háº¡n trÃªn cho gÃ³c lÃ¡i
        """
        self.Kp = Kp
        self.Ki = Ki
        self.Kd = Kd
        self.min_output = min_output
        self.max_output = max_output

        self.prev_error = 0  # Sai sá»‘ trÆ°á»›c Ä‘Ã³
        self.integral = 0  # TÃ­ch phÃ¢n cá»§a sai sá»‘

    def update(self, error):
        """
        Cáº­p nháº­t vÃ  tÃ­nh toÃ¡n Ä‘iá»u khiá»ƒn PID.
        - error: Sai sá»‘ hiá»‡n táº¡i (lateral offset)
        """
        # TÃ­nh Ä‘áº¡o hÃ m vÃ  tÃ­ch phÃ¢n
        derivative = error - self.prev_error
        self.integral += error

        # TÃ­nh toÃ¡n Ä‘iá»u khiá»ƒn PID
        output = self.Kp * error + self.Ki * self.integral + self.Kd * derivative

        # Giá»›i háº¡n output trong khoáº£ng -35 Ä‘áº¿n 35 Ä‘á»™
        output = max(self.min_output, min(self.max_output, output))

        # Cáº­p nháº­t sai sá»‘ vÃ  tráº£ vá» giÃ¡ trá»‹ Ä‘iá»u khiá»ƒn
        self.prev_error = error
        return output


def stanley_control(e, psi, v, k=1.0):
    """
    HÃ m Ä‘iá»u khiá»ƒn Stanley Ä‘á»ƒ tÃ­nh toÃ¡n gÃ³c lÃ¡i.
    - theta_c: HÆ°á»›ng cá»§a xe.
    - k: Há»‡ sá»‘ Ä‘iá»u khiá»ƒn.
    Returns:
    - delta: GÃ³c lÃ¡i cáº§n Ä‘iá»u khiá»ƒn (radian).
    """
    cons = 0.001

    # TÃ­nh toÃ¡n gÃ³c lÃ¡i theo phÆ°Æ¡ng phÃ¡p Stanley
    delta = psi + np.arctan(k * e / (v + cons)) * (180 / np.pi)
    if delta > 35:
        delta = 35
    elif delta < -35:
        delta = -35
    return delta

def send_motor_servo_control(motor_speed, servo_angle):
    try:
        # Gá»­i dá»¯ liá»‡u xuá»‘ng STM32
        send_data = f"M+{motor_speed} S{servo_angle} "
        #ser.write(send_data.encode('utf-8'))
    except Exception as e:
        print(f"[Send] Error: {e}")


def calculate_ct_errors(left, right):
    """
    TÃ­nh toÃ¡n cross track error vÃ  heading error dá»±a trÃªn cÃ¡c phÆ°Æ¡ng trÃ¬nh báº­c hai cho lÃ n trÃ¡i vÃ  pháº£i.

    Parameters:
    - left_fit, right_fit: CÃ¡c há»‡ sá»‘ phÆ°Æ¡ng trÃ¬nh báº­c hai cho lane trÃ¡i vÃ  pháº£i.
    - image_height: Chiá»u cao cá»§a áº£nh (tÃ­nh theo pixel).
    - image_width: Chiá»u rá»™ng cá»§a áº£nh (tÃ­nh theo pixel).

    Returns:
    - cross_track_error: Lá»—i cross track theo pixel.
    - heading_error: Lá»—i heading theo Ä‘á»™.
    """

    # TÃ­nh toÃ¡n tá»a Ä‘á»™ x cá»§a lane trÃ¡i vÃ  pháº£i táº¡i y_eval
    left_lane_x = left[0]
    right_lane_x = right[0]

    # Trung tÃ¢m cá»§a lÃ n Ä‘Æ°á»ng
    lane_center_x = (left_lane_x + right_lane_x) / 2

    # Vá»‹ trÃ­ trung tÃ¢m cá»§a xe, giáº£ sá»­ xe á»Ÿ chÃ­nh giá»¯a áº£nh (x = 320)
    car_position_x = 320  # 320 cho áº£nh cÃ³ kÃ­ch thÆ°á»›c 480x640

    # TÃ­nh toÃ¡n cross track error theo pixel
    cross_track_error = lane_center_x - car_position_x

    return cross_track_error

# Äá»c encoder tá»« serial
def read_encoder():
    global encoder_value
#    while True:
#        try:
            #data = ser.readline().decode('utf-8').strip()
#            data = "E0"
#            if data.startswith("E"):
 #               # Láº¥y giÃ¡ trá»‹ encoder
#                encoder_value = int(data[3:])
#                print(f"Encoder Value: {encoder_value}")
#        except Exception as e:
#            print(f"Error reading encoder: {e}")


def convert_hsv(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)


def HSV_color_selection(image):
    # Chuyá»ƒn áº£nh sang HSV
    converted_image = convert_hsv(image)

    # Mask mÃ u tráº¯ng
    lower_threshold = np.uint8([0, 0, 220])
    upper_threshold = np.uint8([255, 30, 255])
    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)

    # Mask mÃ u vÃ ng
    lower_threshold = np.uint8([0, 10, 10])
    upper_threshold = np.uint8([90, 255, 255])
    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)

    # Káº¿t há»£p mask tráº¯ng vÃ  vÃ ng
    mask = cv2.bitwise_or(white_mask, yellow_mask)
    masked_image = cv2.bitwise_and(image, image, mask=mask)
    img_gray = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)
    blurred_img = cv2.GaussianBlur(img_gray, (7, 7), 0)
    return blurred_img


def nothing(x):
    pass


prevLx = []
prevRx = []
def lane_detection():
    prev_time = time.time()
    while True:

        global lane_offset, curvature, mid, angle_inclination_wrt_x, angle_inclination_wrt_y, prevLx, prevRx,x0,pre_inclination_wrt_y,pre_lane_offset,cur,denta,x_hat,P,step_counter
        success, image = vidcap.read()
        frame = cv2.resize(image, (640, 480))

        ## Choosing points for perspective transformation
        height, width = frame.shape[:2]
        tl = (int(width * 0.75), int(height * 0.45))
        tr = (int(width * 0.25), int(height * 0.45))
        bl = (int(0), int(height))
        br = (int(width), int(height))

        cv2.circle(frame, tl, 5, (0, 0, 255), -1)
        cv2.circle(frame, bl, 5, (0, 0, 255), -1)
        cv2.circle(frame, tr, 5, (0, 0, 255), -1)
        cv2.circle(frame, br, 5, (0, 0, 255), -1)

        ## Aplying perspective transformation
        pts1 = np.float32([bl, br, tl, tr])
        pts2 = np.float32([[0, int(height)], [int(width), int(height)], [int(width), 0], [0, 0]])

        # Matrix to warp the image for birdseye window
        matrix = cv2.getPerspectiveTransform(pts1, pts2)

        transformed_frame = cv2.warpPerspective(frame, matrix, (640, 480))

        ### Object Detection
        # Image Thresholding
        mask = HSV_color_selection(transformed_frame)

        # Histogram
        histogram = np.sum(mask[mask.shape[0] // 2:, :], axis=0)
        midpoint = int(histogram.shape[0] / 2)
        left_base = np.argmax(histogram[:midpoint])
        right_base = np.argmax(histogram[midpoint:]) + midpoint

        # Sliding Window
        y = 472
        lx = []
        rx = []
        slope = 0.0

        msk = mask.copy()

        while y > int(height * 0.55):
            ## Left threshold
            img = mask[y - 35:y, left_base - 30:left_base + 30]
            contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                M = cv2.moments(contour)
                if M["m00"] > 50:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    lx.append(left_base - 30 + cx)
                    cv2.circle(msk, (left_base - 30 + cx, y), 2, (0, 0, 0), -1)
                    left_base = left_base - 30 + cx

            ## Right threshold
            img = mask[y - 35:y, right_base - 30:right_base + 30]
            contours, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                M = cv2.moments(contour)
                if M["m00"] > 50:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    rx.append(right_base - 30 + cx)
                    right_base = right_base - 30 + cx

            cv2.rectangle(msk, (left_base - 30, y), (left_base + 30, y - 35), (255, 0, 0), 2)
            cv2.rectangle(msk, (right_base - 30, y), (right_base + 30, y - 35), (255, 0, 0), 2)
            y -= 35
        print("leng trai", len(lx), "leng phai", len(rx))

        overlay = transformed_frame.copy()

        # Ensure lx and rx are not empty
        if len(lx) == 0:
            lx = prevLx
        else:
            prevLx = lx
        if len(rx) == 0:
            rx = prevRx
        else:
            prevRx = rx

        if len(lx) < 2 and len(rx) > 2:
            y_eval = 430
            right_points = [(rx[i], 470 - i * 35) for i in range(len(rx))]
            right_fit = np.polyfit([p[1] for p in right_points], [p[0] for p in right_points], 2)
            x_right_vals = np.linspace(min([p[1] for p in right_points]), max([p[1] for p in right_points]), 50)
            right_y_vals = right_fit[0] * x_right_vals ** 2 + right_fit[1] * x_right_vals + right_fit[2]
            right_points_on_image = [(int(y), int(x)) for y, x in zip(right_y_vals, x_right_vals)]

            for i in range(len(right_points_on_image) - 1):
                cv2.line(overlay, right_points_on_image[i], right_points_on_image[i + 1], (0, 165, 255),
                         2)  # Cam cho lane pháº£i
            for i in range(5):
                cur[i] =0.4/ (((1 + (2 * right_fit[0] * y_eval + right_fit[1]) ** 2) ** 1.5) / np.abs(
                    2 * right_fit[0]) * 0.00062857)
                y_eval += 10  # Adjust y_eval as required

            right_curvature = ((1 + (2 * right_fit[0] * y_eval + right_fit[1]) ** 2) ** 1.5) / np.abs(
                2 * right_fit[0]) * 0.00062857
            slope = 2 * right_fit[0] * y_eval + right_fit[1]
            anlge_inclination_wrt_y = - np.arctan(slope) * (180 / np.pi)
            print("slope", slope)
            # print("anlge_inclination_wrt_x", anlge_inclination_wrt_x)
            # if (anlge_inclination_wrt_x >= 0):
            #    anlge_inclination_wrt_y = 90 - anlge_inclination_wrt_x

            # elif (anlge_inclination_wrt_x < 0):
            #    anlge_inclination_wrt_y = - (90 - math.fabs(anlge_inclination_wrt_x))

            car_to_right_lane_distance = math.fabs(rx[0] - 320)
            car_to_lane_center = (530 / 2) - car_to_right_lane_distance
            lane_offset = - car_to_lane_center

        elif len(rx) < 2 and len(lx) > 2:
            y_eval = 430
            left_points = [(lx[i], 470 - i * 35) for i in range(len(lx))]
            left_fit = np.polyfit([p[1] for p in left_points], [p[0] for p in left_points], 2)

            x_left_vals = np.linspace(min([p[1] for p in left_points]), max([p[1] for p in left_points]), 50)
            left_y_vals = left_fit[0] * x_left_vals ** 2 + left_fit[1] * x_left_vals + left_fit[2]
            left_points_on_image = [(int(y), int(x)) for y, x in zip(left_y_vals, x_left_vals)]

            for i in range(len(left_points_on_image) - 1):
                cv2.line(overlay, left_points_on_image[i], left_points_on_image[i + 1], (165, 33, 255),
                         2)  # Xanh lÃ¡ cho lane trÃ¡i
            for i in range(5):
                cur[i] = 0.4/(((1 + (2 * left_fit[0] * y_eval + left_fit[1]) ** 2) ** 1.5) / np.abs(
                2 * left_fit[0]) * 0.00062857)
                y_eval += 10  # Adjust y_eval as required
            left_curvature = ((1 + (2 * left_fit[0] * y_eval + left_fit[1]) ** 2) ** 1.5) / np.abs(
                2 * left_fit[0]) * 0.00062857

            slope = 2 * left_fit[0] * y_eval + left_fit[1]
            print("slope", slope)
            anlge_inclination_wrt_y = -np.arctan(slope) * (180 / np.pi)
            # print("anlge_inclination_wrt_x",anlge_inclination_wrt_x)
            # if (anlge_inclination_wrt_x >= 0):
            #    anlge_inclination_wrt_y = 90 - anlge_inclination_wrt_x

            # elif (anlge_inclination_wrt_x < 0):
            #    anlge_inclination_wrt_y = - (90 - math.fabs(anlge_inclination_wrt_x))
            car_to_left_lane_distance = math.fabs(lx[0] - 320)
            car_to_lane_center = (530 / 2) - car_to_left_lane_distance
            lane_offset = car_to_lane_center

        elif len(lx) >= 2 and len(rx) >= 2:
            # Ensure both lx and rx have the same length
            min_length = min(len(lx), len(rx))
            print("min_length   ", min_length)

            # Create a copy of the transformed frame

            # Create the top and bottom points for the quadrilateral
            previus_midpoint = (320, 472)

            midpoints = []  # List to store midpoints

            # Váº½ mid point
            for i in range(min_length):
                if min_length > 1:
                    print("i", i)

                    left = (lx[i], 470 - i * 35)
                    right = (rx[i], 470 - i * 35)

                    cv2.line(overlay, left, right, (0, 255, 0), 1)  # ÄÆ°á»ng mÃ u xanh lÃ¡
                    distance = np.sqrt((right[0] - left[0]) ** 2 + (right[1] - left[1]) ** 2)

                    # TÃ­nh trung Ä‘iá»ƒm giá»¯a left vÃ  right
                    now_midpoint = ((left[0] + right[0]) / 2, (left[1] + right[1]) / 2)

                    # LÆ°u trung Ä‘iá»ƒm vÃ o danh sÃ¡ch
                    midpoints.append(now_midpoint)

                    # Váº½ Ä‘iá»ƒm trung tÃ¢m (mÃ u Ä‘á») lÃªn overlay
                    cv2.circle(overlay, (int(now_midpoint[0]), int(now_midpoint[1])), 5, (0, 0, 255), -1)

                    # Váº½ Ä‘Æ°á»ng tháº³ng tá»« trung Ä‘iá»ƒm trÆ°á»›c Ä‘Ã³ Ä‘áº¿n trung Ä‘iá»ƒm hiá»‡n táº¡i
                    cv2.line(overlay, (int(previus_midpoint[0]), int(previus_midpoint[1])),
                             (int(now_midpoint[0]), int(now_midpoint[1])), (200, 100, 250), 1)
                    # Cáº­p nháº­t mid point
                    previus_midpoint = now_midpoint

                    # In ra chiá»u dÃ i
                    print(f"Distance between is {distance:.2f} pixels")

                    # Draw the filled polygon on the transformed frame
                    alpha = 1  # Opacity factor
                    cv2.addWeighted(overlay, alpha, transformed_frame, 1 - alpha, 0, transformed_frame)

            if len(midpoints) >= 3:
                # Chá»n 3 Ä‘iá»ƒm Ä‘áº§u tiÃªn
                points = np.array(midpoints[:len(midpoints)], dtype=np.float32)

                # Sá»­ dá»¥ng hÃ m cv2.fitLine Ä‘á»ƒ tÃ¬m phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng tháº³ng
                [vx, vy, x0, y0] = cv2.fitLine(points, cv2.DIST_L2, 0, 0.01, 0.01)
                print("vy", vy[0])
                print("vx", vx[0])
                # TÃ­nh toÃ¡n phÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»ng tháº³ng tá»« cÃ¡c tham sá»‘ tÃ¬m Ä‘Æ°á»£c
                slope = vy[0] / vx[0]  # Äá»™ dá»‘c (slope)

                #intercept = y0 - slope * x0  # Giao Ä‘iá»ƒm vá»›i trá»¥c y (intercept)

                anlge_inclination_wrt_x = -np.arctan(slope) * (180 / np.pi)
                mid = 80
                if (anlge_inclination_wrt_x >= 0):
                    anlge_inclination_wrt_y = 90 - anlge_inclination_wrt_x
                    # angle = mid - anlge_inclination_wrt_y
                    # steering_angle = angle

                elif (anlge_inclination_wrt_x < 0):
                    anlge_inclination_wrt_y = - (90 - math.fabs(anlge_inclination_wrt_x))
                    # angle = mid - anlge_inclination_wrt_y
                    # steering_angle = angle

            elif len(midpoints) == 2:

                # Chá»n 2 Ä‘iá»ƒm Ä‘áº§u tiÃªn
                x1, y1 = midpoints[0]
                x2, y2 = midpoints[1]

                # TÃ­nh Ä‘á»™ dá»‘c (slope)
                slope = (y2 - y1) / (x2 - x1)

                # TÃ­nh giao Ä‘iá»ƒm vá»›i trá»¥c y (intercept)
                #intercept = y1 - slope * x1

                anlge_inclination_wrt_x = -np.arctan(slope) * (180 / np.pi)
                mid = 80
                if (anlge_inclination_wrt_x >= 0):
                    anlge_inclination_wrt_y = 90 - anlge_inclination_wrt_x
                    # angle = mid - anlge_inclination_wrt_y
                    # steering_angle = angle

                elif (anlge_inclination_wrt_x < 0):
                    anlge_inclination_wrt_y = - (90 - math.fabs(anlge_inclination_wrt_x))
                    # angle = mid - anlge_inclination_wrt_y
                    # steering_angle = angle

                # Váº½ Ä‘Æ°á»ng tháº³ng tá»« phÆ°Æ¡ng trÃ¬nh
                # left_x = int(150)  # Äiá»ƒm báº¯t Ä‘áº§u (x = 0)
                # left_y = int(slope * left_x + intercept)  # TÃ­nh toÃ¡n y tÆ°Æ¡ng á»©ng

                # right_x = int(440)  # Äiá»ƒm káº¿t thÃºc (x = chiá»u rá»™ng áº£nh)
                # right_y = int(slope * right_x + intercept)  # TÃ­nh toÃ¡n y tÆ°Æ¡ng á»©ng

                # Váº½ Ä‘Æ°á»ng tháº³ng trÃªn áº£nh
                # cv2.line(overlay, (int(left_x), int(left_y)), (int(right_x), int(right_y)), (255, 0, 0), 2)

            left_points = [(lx[i], 470 - i * 35) for i in range(min_length)]
            right_points = [(rx[i], 470 - i * 35) for i in range(min_length)]

            lane_offset = calculate_ct_errors(lx, rx)

            # Khá»›p má»™t Ä‘a thá»©c báº­c 2 vá»›i cÃ¡c Ä‘iá»ƒm lane trÃ¡i vÃ  pháº£i
            left_fit = np.polyfit([p[1] for p in left_points], [p[0] for p in left_points], 2)
            right_fit = np.polyfit([p[1] for p in right_points], [p[0] for p in right_points], 2)

            # Táº¡o cÃ¡c giÃ¡ trá»‹ x cho Ä‘Æ°á»ng trÃ¡i vÃ  pháº£i
            x_left_vals = np.linspace(min([p[1] for p in left_points]), max([p[1] for p in left_points]), 50)
            x_right_vals = np.linspace(min([p[1] for p in right_points]), max([p[1] for p in right_points]), 50)

            # TÃ­nh toÃ¡n y tá»« cÃ¡c giÃ¡ trá»‹ x dá»±a trÃªn Ä‘a thá»©c báº­c 2 Ä‘Ã£ khá»›p
            left_y_vals = left_fit[0] * x_left_vals ** 2 + left_fit[1] * x_left_vals + left_fit[2]
            right_y_vals = right_fit[0] * x_right_vals ** 2 + right_fit[1] * x_right_vals + right_fit[2]

            # Chuyá»ƒn cÃ¡c Ä‘iá»ƒm (x, y) thÃ nh tá»a Ä‘á»™ pixel trÃªn áº£nh
            left_points_on_image = [(int(y), int(x)) for y, x in zip(left_y_vals, x_left_vals)]
            right_points_on_image = [(int(y), int(x)) for y, x in zip(right_y_vals, x_right_vals)]

            for i in range(len(left_points_on_image) - 1):
                cv2.line(overlay, left_points_on_image[i], left_points_on_image[i + 1], (165, 33, 255),
                         2)  # Xanh lÃ¡ cho lane trÃ¡i
                cv2.line(overlay, right_points_on_image[i], right_points_on_image[i + 1], (0, 165, 255),
                         2)  # Cam cho lane pháº£i

            # Calculate the curvature
            y_eval = 470
            for i in range(5):
                cur[i] = 0.4/((((1 + (2 * right_fit[0] * y_eval + right_fit[1]) ** 2) ** 1.5) / np.abs(
                    2 * right_fit[0]) * 0.00062857 + ((1 + (2 * left_fit[0] * y_eval + left_fit[1]) ** 2) ** 1.5) / np.abs(
                2 * left_fit[0]) * 0.00062857 )/2)
                y_eval += 10  # Adjust y_eval as required
            left_curvature = ((1 + (2 * left_fit[0] * y_eval + left_fit[1]) ** 2) ** 1.5) / np.abs(
                2 * left_fit[0]) *  0.000628
            right_curvature = ((1 + (2 * right_fit[0] * y_eval + right_fit[1]) ** 2) ** 1.5) / np.abs(
                2 * right_fit[0])*  0.000628

            print("left_curvature", left_curvature)
            print("right_curvature", right_curvature)
            curvature = (left_curvature + right_curvature) / 2
        else:
            lane_offset = 0
            anlge_inclination_wrt_y = 0

        # Khá»Ÿi táº¡o PID controller
        # pid_controller = PID(Kp=800.0, Ki=0.1, Kd=-0.05)
        # denta= pid_controller.update(lane_offset*0.000628 )
        x0 = np.array([
            [lane_offset*0.000528],
            [(lane_offset - pre_lane_offset)*0.000528 / 0.1],
            [np.radians(anlge_inclination_wrt_y)],
            [(np.radians(anlge_inclination_wrt_y) - pre_inclination_wrt_y) / 0.1]
        ])
        print("Debug x0:")
        print(f"Lane Offset: {x0[0, 0]}")
        print(f"Lane Offset Rate: {x0[1, 0]}")
        print(f"Angle Inclination (rad): {x0[2, 0]}")
        print(f"Angle Inclination Rate (rad/s): {x0[3, 0]}")
        x_hat,P =kalman_step(denta,cur[0],x0)
        x0 =x_hat.flatten()
        step_counter += 1
        denta =  get_nearest_control(x0)
        #denta = mpc_control()
        pre_lane_offset =lane_offset
        pre_inclination_wrt_y = np.radians(anlge_inclination_wrt_y)
        # Stanley controler
        #denta = stanley_control(lane_offset * 0.000628, anlge_inclination_wrt_y, 1.7, k=4)

        steering_angle = mid + denta
        send_motor_servo_control(0, steering_angle)

        alpha = 1  # Opacity factor
        cv2.addWeighted(overlay, alpha, transformed_frame, 1 - alpha, 0, transformed_frame)
        # Display the transformed frame with the highlighted lane
        # cv2.imshow("Transformed Frame with Highlighted Lane", overlay)
        #   # Calculate the end point of the line based on the angle
        line_length = 100  # Length of the line
        end_x = int(320 + line_length * np.sin(np.radians(denta)))
        end_y = int(480 - line_length * np.cos(np.radians(denta)))

        # Inverse perspective transformation to map the lanes back to the original image
        inv_matrix = cv2.getPerspectiveTransform(pts2, pts1)
        original_perpective_lane_image = cv2.warpPerspective(transformed_frame, inv_matrix, (640, 480))

        # Combine the original frame with the lane image
        result = cv2.addWeighted(frame, 1, original_perpective_lane_image, 0.5, 0)

        current_time = time.time()
        fps = 1.0 / (current_time - prev_time)  # FPS = 1 / thá»i gian giá»¯a hai khung hÃ¬nh
        prev_time = current_time  # Cáº­p nháº­t thá»i gian cá»§a khung hÃ¬nh trÆ°á»›c

        # Draw a straight line in the center of the frame pointing with the current angle
        cv2.line(result, (320, 480), (end_x, end_y), (255, 0, 0), 2)
        cv2.line(result, (320, 480), (320, 440), (0, 0, 0), 2)
        # Display the curvature, offset, and angle on the frame
        cv2.putText(result, f'Curvature: {curvature:.2f} m', (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(result, f'Offset: {-lane_offset*0.00528:.6f} m', (30, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(result, f'steering_angle: {steering_angle:.2f} deg', (30, 110), cv2.FONT_HERSHEY_SIMPLEX, 1,
                    (255, 255, 255), 2)
        cv2.putText(result, f'anlge_inclination_wrt_y: {anlge_inclination_wrt_y:.2f} deg', (30, 160),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(result, f'anlge_inclination_wrt_x: {anlge_inclination_wrt_x:.2f} deg', (30, 200),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(result, f'denta: {denta:.2f} ', (30, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(result, f'FPS: {fps:.2f}', (30, 280), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        # cv2.imshow("Original", frame)
        cv2.imshow("Bird's Eye View", transformed_frame)
        # cv2.imshow("Lane Detection - Image Thresholding", mask)
        cv2.imshow("Lane Detection - Sliding Windows", msk)
        cv2.imshow('Lane Detection', result)

        if cv2.waitKey(10) == 27:
            break

    vidcap.release()
    cv2.destroyAllWindows()

def mpc_control_loop():
    global denta
    while True:

        #denta = mpc_control()  # Gá»i hÃ m MPC Control
        time.sleep(0.1)  # Chá» 0.1 giÃ¢y trÆ°á»›c khi gá»i láº¡i

# Táº¡o luá»“ng Ä‘á»ƒ Ä‘iá»u khiá»ƒn mpc



# Táº¡o luá»“ng Ä‘á»ƒ Ä‘á»c encoder
encoder_thread = threading.Thread(target=read_encoder)
encoder_thread.daemon = True  # Äáº£m báº£o luá»“ng nÃ y sáº½ káº¿t thÃºc khi chÆ°Æ¡ng trÃ¬nh chÃ­nh káº¿t thÃºc
encoder_thread.start()

# Táº¡o luá»“ng Ä‘á»ƒ xá»­ lÃ½ lane detection vÃ  Stanley control
lane_detection_thread = threading.Thread(target=lane_detection)
lane_detection_thread.daemon = True
lane_detection_thread.start()

mpc_thread = threading.Thread(target=mpc_control_loop)
mpc_thread.daemon = True  # Äáº£m báº£o dá»«ng khi chÆ°Æ¡ng trÃ¬nh chÃ­nh káº¿t thÃºc
mpc_thread.start()
mpc_init(Ts=0.1)

while True:
    # Thá»±c hiá»‡n cÃ¡c cÃ´ng viá»‡c trong vÃ²ng láº·p chÃ­nh náº¿u cáº§n
    time.sleep(1)